{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D,Activation,Flatten,Dense,Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>manually_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00044347.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002d256b.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname         label  manually_verified\n",
       "0  00044347.wav        Hi-hat                  0\n",
       "1  001ca53d.wav     Saxophone                  1\n",
       "2  002d256b.wav       Trumpet                  0\n",
       "3  0033e230.wav  Glockenspiel                  1\n",
       "4  00353774.wav         Cello                  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000, audio_duration=2):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(d_utils.Sequence):\n",
    "    def __init__(self, config, data_dir, list_IDs, labels=None, \n",
    "                 batch_size=64, preprocessing_fn=lambda x: x):\n",
    "        self.config = config\n",
    "        self.data_dir = data_dir\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "        self.on_epoch_end()\n",
    "        self.dim = self.config.dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        return self.__data_generation(list_IDs_temp)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        \n",
    "    def transform_data(self,data):\n",
    "        if self.config.use_mfcc:\n",
    "            data = librosa.feature.mfcc(data, sr=self.config.sampling_rate,\n",
    "                                               n_mfcc=self.config.n_mfcc)\n",
    "            data = np.expand_dims(data, axis=-1)\n",
    "        elif self.config.use_mel_spec:\n",
    "            data = librosa.feature.melspectrogram(data,sr=self.config.sampling_rate,n_mels=self.config.n_mels)\n",
    "        else:\n",
    "            data = self.preprocessing_fn(data)[:, np.newaxis]\n",
    "        return data\n",
    "    \n",
    "    def adjust_audio_length(self,data,input_length):\n",
    "       # print(\"adjusted audio length\")\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "       # print(len(data))\n",
    "        return data\n",
    "#             if len(data) >= input_length:\n",
    "#                 data = data[:input_length]\n",
    "#             else:\n",
    "#                 data = np.pad(data,input_length-len(data),\"constant\")\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        cur_batch_size = len(list_IDs_temp)\n",
    "        X = np.empty((cur_batch_size, *self.dim))\n",
    "\n",
    "        input_length = self.config.audio_length\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            file_path = self.data_dir + ID\n",
    "            \n",
    "            # Read and Resample the audio\n",
    "            data, _ = librosa.core.load(file_path, sr=self.config.sampling_rate,\n",
    "                                        res_type='kaiser_fast')\n",
    "            \n",
    "            #fixing lengths of files\n",
    "            # Random offset / Padding\n",
    "            data = self.adjust_audio_length(data,input_length)\n",
    "            #other preprocessing\n",
    "            data = self.transform_data(data)\n",
    "         \n",
    "            X[i,] = data\n",
    "\n",
    "        if self.labels is not None:\n",
    "            y = np.empty(cur_batch_size, dtype=int)\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                y[i] = self.labels[ID]\n",
    "            return X, n_utils.to_categorical(y, num_classes=self.config.n_classes)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(train, config, quick_run=False):\n",
    "    if quick_run:\n",
    "        train = train.sample(2000)\n",
    "        config = Config(sampling_rate=100, audio_duration=1, n_folds=2, max_epochs=1)\n",
    "\n",
    "    PREDICTION_FOLDER = \"predictions_1d_conv\"\n",
    "    if not os.path.exists(PREDICTION_FOLDER):\n",
    "        os.mkdir(PREDICTION_FOLDER)\n",
    "    if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "        shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "    skf = StratifiedKFold(train.label_idx, n_folds=config.n_folds)\n",
    "\n",
    "    for i, (train_split, val_split) in enumerate(skf):\n",
    "        train_set = train.iloc[train_split]\n",
    "        val_set = train.iloc[val_split]\n",
    "        checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "        tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%d'%i, write_graph=True)\n",
    "\n",
    "        callbacks_list = [checkpoint, early, tb]\n",
    "        print(\"Fold: \", i)\n",
    "        print(\"#\"*50)\n",
    "        if not quick_run:\n",
    "            model = get_conv_model(config)\n",
    "        else:\n",
    "            model = get_1d_dummy_model(config)\n",
    "        train_generator = DataGenerator(config, 'data/audio_train/', train_set.index, \n",
    "                                        train_set.label_idx, batch_size=64,\n",
    "                                        preprocessing_fn=normalize_audio)\n",
    "        val_generator = DataGenerator(config, 'data/audio_train/', val_set.index, \n",
    "                                      val_set.label_idx, batch_size=64,\n",
    "                                      preprocessing_fn=normalize_audio)\n",
    "\n",
    "        history = model.fit_generator(train_generator, callbacks=callbacks_list, validation_data=val_generator,\n",
    "                                      epochs=config.max_epochs, use_multiprocessing=True, workers=6, max_queue_size=20)\n",
    "\n",
    "        model.load_weights('best_%d.h5'%i)\n",
    "\n",
    "        # Save train predictions\n",
    "        train_generator = DataGenerator(config, 'data/audio_train/', train.index, batch_size=128,\n",
    "                                        preprocessing_fn=audio_norm)\n",
    "        predictions = model.predict_generator(train_generator, use_multiprocessing=True, \n",
    "                                              workers=6, max_queue_size=20, verbose=1)\n",
    "        np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "        # Save test predictions\n",
    "        test_generator = DataGenerator(config, 'data/audio_test/', test.index, batch_size=128,\n",
    "                                        preprocessing_fn=audio_norm)\n",
    "        predictions = model.predict_generator(test_generator, use_multiprocessing=True, \n",
    "                                              workers=6, max_queue_size=20, verbose=1)\n",
    "        np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "        #Make a submission file\n",
    "        top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "        predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "        test['label'] = predicted_labels\n",
    "        test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_dummy_model(config):\n",
    "    nb_class = 41\n",
    "    input_length = sampling_rate*audio_duration\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(nb_filter=512, filter_length=1, input_shape=(input_length, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = optimizers.Adam()\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    model = get_model()\n",
    "    model.fit(X_train,y_Train)\n",
    "    model.save('cnn_audio_tagger.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['fname'].apply(lambda fname: )\n",
    "y_train = train[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(X_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
